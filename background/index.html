<!DOCTYPE html> <html lang="en"> <head> <script async src="https://www.googletagmanager.com/gtag/js?id=G-0MXMBEN63M"></script> <script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-0MXMBEN63M");</script> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>background | AI fairness</title> <meta name="author" content="AI fairness"/> <meta name="description" content="ML Neophyte site. ML Neophyte site. "/> <meta name="keywords" content="Analytics, AI, ML, Big Data, Decision Support Systems, Software & System Design"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚛️</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://chakrs.github.io/background/"> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://chakrs.github.io/buildfairai/">AI fairness</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/background/">background<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/framework/">framework</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/tools/">tools</a> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">background</h1> <p class="post-description"></p> </header> <article> <p>In recent years, artificial intelligence (AI) has made astounding strides, transforming numerous facets of society. However, along with its promise for transformation, issues with fairness and bias have surfaced. AI fairness, a rapidly growing field of research, aims to address the ethical and social implications of AI algorithms and their potential to perpetuate or amplify societal biases. Here we provide a short review of the background of AI fairness, delving into its historical context, key challenges, and the current state of research in this critical domain.</p> <h3 id="historical-context">Historical Context</h3> <p>The origins of AI fairness can be traced back to the civil rights movement in the mid-20th century, when discriminatory practices based on race, gender, and other protected attributes were actively challenged. Over time, the emergence of AI technologies highlighted the need to ensure fairness, as algorithms began to shape decisions in domains such as hiring, lending, and criminal justice. Early research in AI fairness focused on statistical parity, aiming to minimize disparities in outcomes among different demographic groups.</p> <h3 id="key-challenges-in-ai-fairness">Key Challenges in AI Fairness</h3> <p><strong>Bias in Training Data:</strong> Biases can emerge from historical data that reflects societal prejudices and inequalities. AI systems trained on biased data can perpetuate and amplify existing disparities, leading to unfair outcomes. Addressing this challenge involves careful data collection, preprocessing techniques, and diverse representation to ensure fairness.</p> <p><strong>Algorithmic Transparency:</strong> Many AI algorithms are complex and often considered as “black boxes,” making it challenging to understand the decision-making process and identify potential biases. Ensuring transparency and interpretability of algorithms is essential for detecting and rectifying biases effectively.</p> <p><strong>Trade-offs and Conflicting Objectives:</strong> Fairness is often a multidimensional concept, and achieving fairness in one aspect may result in trade-offs in other areas. Balancing fairness with other objectives, such as accuracy and efficiency, requires careful consideration to avoid unintended consequences.</p> <h2 id="current-state-of-research">Current State of Research</h2> <p>The research on AI fairness has witnessed substantial growth and diversification in recent years. Academics, policymakers, and industry experts have contributed to the development of various fairness measures and techniques. Some notable approaches include:</p> <p><strong>Pre-processing Techniques:</strong> Methods like reweighting and sampling are employed to adjust the training data to reduce biases before feeding it into AI models.</p> <p><strong>In-processing Techniques:</strong> Fairness-aware algorithms are designed to mitigate biases during the training process by optimizing fairness metrics alongside accuracy.</p> <p><strong>Post-processing Techniques:</strong> After the model is trained, post-processing techniques are applied to adjust the decision boundaries or outcomes to achieve fairness.</p> <p>Additionally, interdisciplinary collaborations between computer scientists, social scientists, ethicists, and legal experts have become essential for developing comprehensive frameworks that integrate technical solutions with legal and ethical considerations.</p> <p>AI fairness has emerged as a critical field of research due to the profound influence of AI technologies on society. Addressing biases and ensuring fairness in AI systems is paramount for preventing discrimination, promoting equal opportunities, and upholding ethical standards. As the field continues to evolve, ongoing research and collaborations across disciplines will be crucial in developing robust frameworks, methodologies, and guidelines for ensuring fairness in AI algorithms. By actively addressing the challenges and advancing the research in AI fairness, we can work towards a more equitable and inclusive future.</p> </article> </div> </div> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script src="/assets/js/zoom.js"></script> <script src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>